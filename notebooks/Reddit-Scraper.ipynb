{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.1.2-py3-none-any.whl (155 kB)\n",
      "Collecting websocket-client>=0.54.0\n",
      "  Using cached websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting prawcore<2.0,>=1.5.0\n",
      "  Using cached prawcore-1.5.0-py3-none-any.whl (15 kB)\n",
      "Collecting update-checker>=0.18\n",
      "  Using cached update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: six in c:\\users\\vanki\\anaconda3\\lib\\site-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\vanki\\anaconda3\\lib\\site-packages (from prawcore<2.0,>=1.5.0->praw) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vanki\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\vanki\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\vanki\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\vanki\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (2.10)\n",
      "Installing collected packages: websocket-client, prawcore, update-checker, praw\n",
      "Successfully installed praw-7.1.2 prawcore-1.5.0 update-checker-0.18.0 websocket-client-0.57.0\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessing the reddit api\n",
    "DATE = '2021-02-11'\n",
    "os.makedirs(DATE+\"/\")\n",
    "\n",
    "# Look into async praw https://www.reddit.com/r/redditdev/comments/hsn2km/praw_now_has_asynchronous_support_with_async_praw/\n",
    "\n",
    "reddit = praw.Reddit(client_id=\"9zti0sA9D1o4YA\",      # your client id\n",
    "                     client_secret=\"vZiCrrO34lkd_55x96FFS1pyeM7RUQ\",  #your client secret\n",
    "                     user_agent=\"scrape-subreddits-lol\", #user agent name\n",
    "                     username = \"SpaidaTaiga\",     # your reddit username\n",
    "                     password = \"*K0l1K0\",\n",
    "                     check_for_async = False)     # your reddit password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = ['politics', 'uspolitics', 'norge', 'denmark', 'canada', 'polska'] # make a list of subreddits you want to scrape the data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sub:\n",
    "    \n",
    "    subreddit = reddit.subreddit(s)   # Chosing the subreddit\n",
    "    \n",
    "    ########################################\n",
    "    #   CREATING DICTIONARY TO STORE THE DATA WHICH WILL BE CONVERTED TO A DATAFRAME\n",
    "    ########################################\n",
    "\n",
    "    #   NOTE: ALL THE POST DATA AND COMMENT DATA WILL BE SAVED IN TWO DIFFERENT\n",
    "    #   DATASETS AND LATER CAN BE MAPPED USING IDS OF POSTS/COMMENTS AS WE WILL \n",
    "    #   BE CAPTURING ALL IDS THAT COME IN OUR WAY\n",
    "\n",
    "    post_dict = {\n",
    "        \"title\" : [],   #title of the post\n",
    "#         \"score\" : [],   # score of the post\n",
    "        \"id\" : [],      # unique id of the post\n",
    "#         \"url\" : [],     #url of the post\n",
    "#         \"comms_num\": [],   #the number of comments on the post\n",
    "#         \"created\" : [],  #timestamp of the post\n",
    "        \"body\" : []         # the descriptionof post\n",
    "    }\n",
    "    comments_dict = {\n",
    "        \"comment_id\" : [],      #unique comm id\n",
    "        \"comment_parent_id\" : [],   # comment parent id\n",
    "        \"comment_body\" : [],   # text in comment\n",
    "        \"comment_link_id\" : []  #link to the comment\n",
    "    }\n",
    "    for submission in subreddit.hot(limit=100):\n",
    "        post_dict[\"title\"].append(submission.title)\n",
    "#             post_dict[\"score\"].append(submission.title)\n",
    "        post_dict[\"id\"].append(submission.id)\n",
    "#             post_dict[\"url\"].append(submission.title)\n",
    "#             post_dict[\"comms_num\"].append(submission.title)\n",
    "#         post_dict[\"created\"].append(submission.title)\n",
    "        if submission.selftext:\n",
    "            post_dict[\"body\"].append(submission.selftext)\n",
    "        else:\n",
    "            post_dict[\"body\"].append(submission.url)\n",
    "\n",
    "        ##### Acessing comments on the post\n",
    "        submission.comments.replace_more(limit = None)\n",
    "        for comment in submission.comments.list():\n",
    "            comments_dict[\"comment_id\"].append(comment.id)\n",
    "            comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "            comments_dict[\"comment_body\"].append(comment.body)\n",
    "            comments_dict[\"comment_link_id\"].append(comment.link_id)\n",
    "        \n",
    "    post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "    post_comments.to_csv(DATE + \"/\" + s+\"_comments_\"+\"subreddit.csv\")\n",
    "    post_data = pd.DataFrame(post_dict)\n",
    "    post_data.to_csv(DATE + \"/\" + s+\"_\" +\"subreddit.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long does it take to run? - 1000 hot posts from each day in 6 subreddits\n",
    "## Started ~16:07, 04-02-2021\n",
    "## Politics done:\n",
    "## US done:\n",
    "## NO done:\n",
    "## DK done:\n",
    "## CA done:\n",
    "## PL done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
