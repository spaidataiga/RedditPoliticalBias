{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For classifier input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>body</th>\n",
       "      <th>sex</th>\n",
       "      <th>NEL</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "      <th>len</th>\n",
       "      <th>processed_sub100000</th>\n",
       "      <th>processed_subsmaller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40053</td>\n",
       "      <td>It's Ephebophilia.   Pedophilia is what Schiff...</td>\n",
       "      <td>female</td>\n",
       "      <td>Q235349</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>it s ephebophilia . pedophilia is what schiff ...</td>\n",
       "      <td>['it', 's', 'ephebophilia', '.', 'pedophilia',...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>['it', 's', 'unk', '.', 'pedophilia', 'is', 'w...</td>\n",
       "      <td>['it', 's', 'unk', '.', 'pedophilia', 'is', 'w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5714224</td>\n",
       "      <td>[NAME] didn't switch parties.  [NAME] declared...</td>\n",
       "      <td>male</td>\n",
       "      <td>Q1714165</td>\n",
       "      <td>politics</td>\n",
       "      <td>name didn t switch parties . name declared na...</td>\n",
       "      <td>['', 'name', 'didn', 't', 'switch', 'parties',...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>['', 'name', 'didn', 't', 'switch', 'parties',...</td>\n",
       "      <td>['', 'name', 'didn', 't', 'switch', 'parties',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3974237</td>\n",
       "      <td>What if we just attack [NAME]’s Dem challenger...</td>\n",
       "      <td>male</td>\n",
       "      <td>Q22212</td>\n",
       "      <td>politics</td>\n",
       "      <td>what if we just attack name s dem challenger f...</td>\n",
       "      <td>['what', 'if', 'we', 'just', 'attack', 'name',...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>['what', 'if', 'we', 'just', 'attack', 'name',...</td>\n",
       "      <td>['what', 'if', 'we', 'just', 'attack', 'name',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5437084</td>\n",
       "      <td>I also wonder if [NAME] knew about it, or peop...</td>\n",
       "      <td>male</td>\n",
       "      <td>Q632321</td>\n",
       "      <td>politics</td>\n",
       "      <td>i also wonder if name knew about it or people ...</td>\n",
       "      <td>['i', 'also', 'wonder', 'if', 'name', 'knew', ...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>['i', 'also', 'wonder', 'if', 'name', 'knew', ...</td>\n",
       "      <td>['i', 'also', 'wonder', 'if', 'name', 'knew', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1756989</td>\n",
       "      <td>Superiority complex.And then some. Are you fa...</td>\n",
       "      <td>female</td>\n",
       "      <td>Q214475</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>superiority complex . and then some . are you ...</td>\n",
       "      <td>['superiority', 'complex', '.', 'and', 'then',...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>['superiority', 'complex', '.', 'and', 'then',...</td>\n",
       "      <td>['superiority', 'complex', '.', 'and', 'then',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               body     sex  \\\n",
       "0       40053  It's Ephebophilia.   Pedophilia is what Schiff...  female   \n",
       "1     5714224  [NAME] didn't switch parties.  [NAME] declared...    male   \n",
       "2     3974237  What if we just attack [NAME]’s Dem challenger...    male   \n",
       "3     5437084  I also wonder if [NAME] knew about it, or peop...    male   \n",
       "4     1756989   Superiority complex.And then some. Are you fa...  female   \n",
       "\n",
       "        NEL   subreddit                                               text  \\\n",
       "0   Q235349  The_Donald  it s ephebophilia . pedophilia is what schiff ...   \n",
       "1  Q1714165    politics   name didn t switch parties . name declared na...   \n",
       "2    Q22212    politics  what if we just attack name s dem challenger f...   \n",
       "3   Q632321    politics  i also wonder if name knew about it or people ...   \n",
       "4   Q214475  The_Donald  superiority complex . and then some . are you ...   \n",
       "\n",
       "                                           processed   len  \\\n",
       "0  ['it', 's', 'ephebophilia', '.', 'pedophilia',...  14.0   \n",
       "1  ['', 'name', 'didn', 't', 'switch', 'parties',...  62.0   \n",
       "2  ['what', 'if', 'we', 'just', 'attack', 'name',...  16.0   \n",
       "3  ['i', 'also', 'wonder', 'if', 'name', 'knew', ...  20.0   \n",
       "4  ['superiority', 'complex', '.', 'and', 'then',...  91.0   \n",
       "\n",
       "                                 processed_sub100000  \\\n",
       "0  ['it', 's', 'unk', '.', 'pedophilia', 'is', 'w...   \n",
       "1  ['', 'name', 'didn', 't', 'switch', 'parties',...   \n",
       "2  ['what', 'if', 'we', 'just', 'attack', 'name',...   \n",
       "3  ['i', 'also', 'wonder', 'if', 'name', 'knew', ...   \n",
       "4  ['superiority', 'complex', '.', 'and', 'then',...   \n",
       "\n",
       "                                processed_subsmaller  \n",
       "0  ['it', 's', 'unk', '.', 'pedophilia', 'is', 'w...  \n",
       "1  ['', 'name', 'didn', 't', 'switch', 'parties',...  \n",
       "2  ['what', 'if', 'we', 'just', 'attack', 'name',...  \n",
       "3  ['i', 'also', 'wonder', 'if', 'name', 'knew', ...  \n",
       "4  ['superiority', 'complex', '.', 'and', 'then',...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"results/validation_set.csv\")\n",
    "#test.to_csv(\"results/test_set.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'Unnamed: 0': 'index'}, axis=1, inplace=True)\n",
    "clean = df[['index','body','sex']]\n",
    "clean.to_csv(\"valid_set_clean.tsv\",sep='\\t',index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>body</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40053</td>\n",
       "      <td>It's Ephebophilia.   Pedophilia is what Schiff...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5714224</td>\n",
       "      <td>[NAME] didn't switch parties.  [NAME] declared...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3974237</td>\n",
       "      <td>What if we just attack [NAME]’s Dem challenger...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5437084</td>\n",
       "      <td>I also wonder if [NAME] knew about it, or peop...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1756989</td>\n",
       "      <td>Superiority complex.And then some. Are you fa...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               body     sex\n",
       "0    40053  It's Ephebophilia.   Pedophilia is what Schiff...  female\n",
       "1  5714224  [NAME] didn't switch parties.  [NAME] declared...    male\n",
       "2  3974237  What if we just attack [NAME]’s Dem challenger...    male\n",
       "3  5437084  I also wonder if [NAME] knew about it, or peop...    male\n",
       "4  1756989   Superiority complex.And then some. Are you fa...  female"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results/test_set.csv\")\n",
    "df.rename({'Unnamed: 0': 'index'}, axis=1, inplace=True)\n",
    "clean = df[['index','body','sex', 'subreddit']]\n",
    "clean.to_csv(\"test_set_clean.tsv\",sep='\\t',index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-partisan Nominal Bias comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for name use cross-partisan comparison\n",
    "\n",
    "df = pd.read_csv(\"all_comments.csv\")\n",
    "\n",
    "sub = df[['subreddit','sex', 'given_name_used',\n",
    "       'family_name_used', 'full_name_used', 'nickname_used']]\n",
    "\n",
    "left = ['Liberal', 'SocialDemocracy', 'socialism', 'alltheleft', 'neoliberal', 'democrats']\n",
    "right = ['Libertarian', 'Conservative', 'Republican']\n",
    "alt_right = ['The_Donald']\n",
    "maps = {}\n",
    "for sr in left:\n",
    "    maps[sr] = 'left'\n",
    "for sr in right:\n",
    "    maps[sr] = 'right'\n",
    "maps['The_Donald'] = 'alt_right'\n",
    "sub['group'] = sub['subreddit'].map(maps)\n",
    "sub.dropna(subset=['group'], inplace=True)\n",
    "\n",
    "#sub.melt(id_vars=['sex','group'], value_vars=['given_name_used','family_name_used', 'full_name_used', 'nickname_used'], var_name='Name_used')\n",
    "sub[['given_name_used','family_name_used', 'full_name_used', 'nickname_used']].idxmax(axis=1)\n",
    "sub['name'] = sub[['given_name_used','family_name_used', 'full_name_used', 'nickname_used']].astype(int).idxmax(axis=1)\n",
    "\n",
    "sub = sub[sub['sex'].isin(['male', 'female'])]\n",
    "sub.to_csv(\"names_used.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanki\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8111768, 9)\n",
      "5678237.6\n",
      "male      0.880532\n",
      "female    0.119468\n",
      "Name: sex, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"results/total.csv\")\n",
    "df = df[df.sex.isin(['male','female'])]\n",
    "print(df.shape)\n",
    "print(df.shape[0]*0.7)\n",
    "print(df.sex.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3208707"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.NEL.value_counts()[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6952769112726104"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5639925/8111768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [0,2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21, 22, 23, 25, 26, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5639925"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.NEL.value_counts()[entities].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "female    0.119408\n",
       "male      0.880592\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = df.groupby('NEL').sex.value_counts().sort_values(ascending=False)[entities]\n",
    "sub.unstack(level=0).sum(axis=1) / sub.unstack(level=0).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male      0.88053\n",
      "female    0.11947\n",
      "Name: sex, dtype: float64\n",
      "male      0.88026\n",
      "female    0.11974\n",
      "Name: sex, dtype: float64\n",
      "1235921\n",
      "1235922\n"
     ]
    }
   ],
   "source": [
    "ent_ids= [i[0] for i in sub.index]\n",
    "train = df[df['NEL'].isin(ent_ids)]\n",
    "test_valid = df[~df['NEL'].isin(ent_ids)]\n",
    "train.to_csv(\"results/train_set.csv\", index=False)\n",
    "shuffled = test_valid.sample(frac=1)\n",
    "valid = shuffled.iloc[:test_valid.shape[0]//2]\n",
    "test = shuffled.iloc[test_valid.shape[0]//2:]\n",
    "print(test.sex.value_counts(normalize=True))\n",
    "print(valid.sex.value_counts(normalize=True))\n",
    "print(valid.shape[0])\n",
    "print(test.shape[0])\n",
    "valid.to_csv(\"results/validation_set.csv\")\n",
    "test.to_csv(\"results/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(n=1000000).to_csv(\"results/train_subset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = pd.read_csv('train_set.csv')\n",
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "total['processed'] = total['processed'].map(literal_eval)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = Word2Vec(sentences=total['processed'], \n",
    "                 sg=1, \n",
    "                 size=100,  \n",
    "                 workers=4)\n",
    "\n",
    "print(f'Time taken : {(time.time() - start_time) / 60:.2f} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('100d_embeds.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109692"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'name', 'goes', 'to', 'ufc']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.wv.vocab.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ftfy', 0.7760351300239563),\n",
       " ('smh', 0.678533136844635),\n",
       " ('smdh', 0.6585896611213684),\n",
       " ('amirite', 0.635604977607727),\n",
       " ('nope', 0.6278433203697205),\n",
       " ('jfc', 0.6257655620574951),\n",
       " ('ffs', 0.6208240985870361),\n",
       " ('whatttt', 0.6204562187194824),\n",
       " ('urlurl', 0.6194939613342285),\n",
       " ('lol', 0.6182695031166077)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original code to process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(\"\\n\", \" \", s)\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1 \", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    #s = re.sub(r\"[\\d]+\", \"NUM\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        if len(sentence.split(' ')) < 4:\n",
    "            return\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addSentenceNew(self,lst):\n",
    "        if len(lst) < 4:\n",
    "            return\n",
    "        for word in lst:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "def createDic(df):\n",
    "    df['text'] = df.body.map(normalizeString)\n",
    "    input = Lang()\n",
    "    print(\"Counting words...\")\n",
    "    for dp in df.body:\n",
    "        input.addSentence(dp)\n",
    "    print(\"Counted words:\")\n",
    "    print(input.n_words)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>sex</th>\n",
       "      <th>NEL</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1424871</th>\n",
       "      <td>something like 30-40% of latinos vote republi...</td>\n",
       "      <td>male</td>\n",
       "      <td>Q22686</td>\n",
       "      <td>politics</td>\n",
       "      <td>something like of latinos vote republicansame ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424872</th>\n",
       "      <td>[NAME] is your friend</td>\n",
       "      <td>male</td>\n",
       "      <td>Q312015</td>\n",
       "      <td>politics</td>\n",
       "      <td>name is your friend</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424873</th>\n",
       "      <td>a belief that the 1987 railroad track deaths ...</td>\n",
       "      <td>male</td>\n",
       "      <td>Q1124</td>\n",
       "      <td>politics</td>\n",
       "      <td>a belief that the railroad track deaths of kev...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424874</th>\n",
       "      <td>[NAME] really is the GOAT</td>\n",
       "      <td>male</td>\n",
       "      <td>Q22686</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>name really is the goat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424875</th>\n",
       "      <td>Literally Scooby-Doo level shit right here.\\n\\...</td>\n",
       "      <td>female</td>\n",
       "      <td>Q6294</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>literally scooby doo level shit right here . n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171121</th>\n",
       "      <td>Labour voted against most of the deals that wh...</td>\n",
       "      <td>male</td>\n",
       "      <td>Q291169</td>\n",
       "      <td>unitedkingdom</td>\n",
       "      <td>labour voted against most of the deals that wh...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171122</th>\n",
       "      <td>Didnt a report come out about the FBI bias jus...</td>\n",
       "      <td>male</td>\n",
       "      <td>Q22212</td>\n",
       "      <td>politics</td>\n",
       "      <td>didnt a report come out about the fbi bias jus...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171123</th>\n",
       "      <td>Well, you know how media coverage works...we h...</td>\n",
       "      <td>male</td>\n",
       "      <td>Q22686</td>\n",
       "      <td>canada</td>\n",
       "      <td>well you know how media coverage works . . . w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171124</th>\n",
       "      <td>I do not want to see [NAME] win the nomination...</td>\n",
       "      <td>male</td>\n",
       "      <td>Q785842</td>\n",
       "      <td>politics</td>\n",
       "      <td>i do not want to see name win the nomination b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8171125</th>\n",
       "      <td>[NAME] is batshit crazy and thinks [NAME]’s th...</td>\n",
       "      <td>male</td>\n",
       "      <td>Q22686</td>\n",
       "      <td>politics</td>\n",
       "      <td>name is batshit crazy and thinks name s the s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6746255 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      body     sex      NEL  \\\n",
       "1424871   something like 30-40% of latinos vote republi...    male   Q22686   \n",
       "1424872                              [NAME] is your friend    male  Q312015   \n",
       "1424873   a belief that the 1987 railroad track deaths ...    male    Q1124   \n",
       "1424874                          [NAME] really is the GOAT    male   Q22686   \n",
       "1424875  Literally Scooby-Doo level shit right here.\\n\\...  female    Q6294   \n",
       "...                                                    ...     ...      ...   \n",
       "8171121  Labour voted against most of the deals that wh...    male  Q291169   \n",
       "8171122  Didnt a report come out about the FBI bias jus...    male   Q22212   \n",
       "8171123  Well, you know how media coverage works...we h...    male   Q22686   \n",
       "8171124  I do not want to see [NAME] win the nomination...    male  Q785842   \n",
       "8171125  [NAME] is batshit crazy and thinks [NAME]’s th...    male   Q22686   \n",
       "\n",
       "             subreddit                                               text  \\\n",
       "1424871       politics  something like of latinos vote republicansame ...   \n",
       "1424872       politics                                name is your friend   \n",
       "1424873       politics  a belief that the railroad track deaths of kev...   \n",
       "1424874     The_Donald                            name really is the goat   \n",
       "1424875     The_Donald  literally scooby doo level shit right here . n...   \n",
       "...                ...                                                ...   \n",
       "8171121  unitedkingdom  labour voted against most of the deals that wh...   \n",
       "8171122       politics  didnt a report come out about the fbi bias jus...   \n",
       "8171123         canada  well you know how media coverage works . . . w...   \n",
       "8171124       politics  i do not want to see name win the nomination b...   \n",
       "8171125       politics   name is batshit crazy and thinks name s the s...   \n",
       "\n",
       "        processed  \n",
       "1424871       NaN  \n",
       "1424872       NaN  \n",
       "1424873       NaN  \n",
       "1424874       NaN  \n",
       "1424875       NaN  \n",
       "...           ...  \n",
       "8171121       NaN  \n",
       "8171122       NaN  \n",
       "8171123       NaN  \n",
       "8171124       NaN  \n",
       "8171125       NaN  \n",
       "\n",
       "[6746255 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[new.processed.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-295f75d2c217>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new['processed'] = np.nan\n",
      "C:\\Users\\vanki\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\vanki\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-295f75d2c217>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'processed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1635\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1637\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_single_block\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[0;32m   3471\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3472\u001b[0m                     \u001b[1;31m# otherwise, either self or ref has swapped in new arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3473\u001b[1;33m                     \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3474\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m                     \u001b[1;31m# GH#33675 we have swapped in a new array, so parent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   3429\u001b[0m         \"\"\"\n\u001b[0;32m   3430\u001b[0m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3431\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3433\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36miset\u001b[1;34m(self, loc, value)\u001b[0m\n\u001b[0;32m   1108\u001b[0m             \u001b[0mblk_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_store\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m                 \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_getitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                 \u001b[0munfit_mgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Substitute overtly gendered words\n",
    "new['processed'] = np.nan\n",
    "for i in range(new.shape[0]):\n",
    "    words = []\n",
    "    for word in new.text.iloc[i].split(' '):\n",
    "        # Replace OBVIOUSLY GENDERED words\n",
    "        if word in subs.keys():\n",
    "            words.append(subs[word])\n",
    "        else:\n",
    "            words.append(word)\n",
    "    new['processed'].iloc[i] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recount words\n",
    "lang = createDic(new)\n",
    "#originally 500,000ish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OCC = 50\n",
    "c=0\n",
    "for word in lang.word2index:\n",
    "    if lang.word2count[word] > 50:\n",
    "        c+=1\n",
    "print(c)\n",
    "#originally 111000ish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNewDic(df):\n",
    "    input = Lang()\n",
    "    print(\"Counting words...\")\n",
    "    for dp in df.processed:\n",
    "        input.addSentenceNew(dp)\n",
    "    print(\"Counted words:\")\n",
    "    print(input.n_words)\n",
    "    return input\n",
    "lang_new = createNewDic(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OCC = 50\n",
    "c=0\n",
    "for word in lang_new.word2index:\n",
    "    if lang_new.word2count[word] > 50:\n",
    "        c+=1\n",
    "print(c)\n",
    "#originally 111000ish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove comments <4 words\n",
    "new['len'] = new.processed.map(len)\n",
    "new2 = new[new['len']> 4]\n",
    "del new\n",
    "print(new2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one with only words than appear >50 words (so we have two columns. One can be combined with pre-made gLove vectors!)\n",
    "new2['processed_sub100000'] = ''\n",
    "for i in range(new2.shape[0]):\n",
    "    words = []\n",
    "    for word in new2.processed:\n",
    "        if lang_new.word2count[word] < 50:\n",
    "            words.append['unk']\n",
    "        else:\n",
    "            words.append[word]\n",
    "    new2['processed_sub100000'].iloc[i] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2.to_csv(\"interim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5718148"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new2.NEL.value_counts()[:17].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2452977"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new2.NEL.value_counts()[17:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide train/valid/test set!\n",
    "# How could I divide this to test cross-partisan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5719788.199999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new2.shape[0]*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanki\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['body', 'sex', 'NEL', 'subreddit', 'text', 'processed', 'len',\n",
       "       'processed_sub100000', 'processed_subsmaller'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"results/total.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.subreddit.str.startswith('Q')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.sex.isin(['male','female'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.len = df.len.map(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.27509637849603"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.len.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.43451905738064"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.len.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
